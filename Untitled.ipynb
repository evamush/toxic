{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "np.random.seed(32)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./dataset/train.csv\", header = 0)\n",
    "test = pd.read_csv(\"./dataset/test.csv\", header = 0)\n",
    "embedding_path = \"./dataset/crawl-300d-2M.vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a1440b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1411"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "wordcounts = []\n",
    "for i in range(len(train)):\n",
    "    wordcounts.append(len(train.comment_text[i].split()))\n",
    "lens = pd.Series(wordcounts)\n",
    "lens.hist()\n",
    "plt.show()\n",
    "max(wordcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "max_features = 100000\n",
    "max_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "\n",
    "train[\"comment_text\"].fillna(\"no comment\")\n",
    "test[\"comment_text\"].fillna(\"no comment\")\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lens = train.comment_text.str.len()\n",
    "lens.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "raw_text_train = X_train[\"comment_text\"].str.lower()\n",
    "raw_text_valid = X_valid[\"comment_text\"].str.lower() \n",
    "raw_text_test = test[\"comment_text\"].str.lower()\n",
    "\n",
    "tk = Tokenizer(num_words = max_features, lower = True)\n",
    "tk.fit_on_texts(raw_text_train)\n",
    "X_train[\"comment_seq\"] = tk.texts_to_sequences(raw_text_train)\n",
    "X_valid[\"comment_seq\"] = tk.texts_to_sequences(raw_text_valid)\n",
    "test[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test)\n",
    "\n",
    "X_train = pad_sequences(X_train.comment_seq, maxlen = max_len)\n",
    "X_valid = pad_sequences(X_valid.comment_seq, maxlen = max_len)\n",
    "test = pad_sequences(test.comment_seq, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
    "\n",
    "file_path = \"best_model.hdf5\"\n",
    "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                              save_best_only = True, mode = \"min\")\n",
    "ra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n",
    "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "\n",
    "def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n",
    "    inp = Input(shape = (max_len,))\n",
    "    x = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    x = SpatialDropout1D(dr)(x)\n",
    "\n",
    "    x = Bidirectional(GRU(units, return_sequences = True))(x)\n",
    "    x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    x = concatenate([avg_pool, max_pool])\n",
    "\n",
    "    x = Dense(6, activation = \"sigmoid\")(x)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(X_train, Y_train, batch_size = 128, epochs = 4, validation_data = (X_valid, Y_valid), \n",
    "                        verbose = 1, callbacks = [ra_val, check_point, early_stop])\n",
    "    model = load_model(file_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1204: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/4\n",
      " 22784/143613 [===>..........................] - ETA: 2:21:40 - loss: 0.0964 - acc: 0.9724"
     ]
    }
   ],
   "source": [
    "model = build_model(lr = 1e-3, lr_d = 0, units = 128, dr = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 622s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(test, batch_size = 1024, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7533.2721610069275] Completed!\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(\"./dataset/sample_submission.csv\")\n",
    "submission[list_classes] = (pred_test)\n",
    "submission.to_csv(\"submission_test.csv\", index = False)\n",
    "print(\"[{}] Completed!\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.989217</td>\n",
       "      <td>0.411576</td>\n",
       "      <td>0.967211</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.913681</td>\n",
       "      <td>0.489868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.989217      0.411576  0.967211  0.003455  0.913681   \n",
       "1  0000247867823ef7  0.000137      0.000008  0.000068  0.000004  0.000108   \n",
       "2  00013b17ad220c46  0.000286      0.000072  0.000148  0.000026  0.000300   \n",
       "3  00017563c3f7919a  0.000019      0.000004  0.000026  0.000008  0.000034   \n",
       "4  00017695ad8997eb  0.002390      0.000092  0.000650  0.000188  0.000583   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.489868  \n",
       "1       0.000010  \n",
       "2       0.000107  \n",
       "3       0.000004  \n",
       "4       0.000042  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571/159571 [==============================] - 631s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./dataset/train.csv\", header = 0)\n",
    "train_id = train[\"id\"]\n",
    "raw_train = train[\"comment_text\"].str.lower()\n",
    "train[\"comment_seq\"] = tk.texts_to_sequences(raw_train)\n",
    "train = pad_sequences(train.comment_seq, maxlen = max_len)\n",
    "\n",
    "pred_train = model.predict(train, batch_size = 1024, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns = [\"id\",\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "submission[\"id\"] = train_id\n",
    "submission[list_classes] = (pred_train)\n",
    "submission.to_csv(\"submission_train.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_union\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train = pd.read_csv(\"./dataset/train.csv\", header = 0)\n",
    "test = pd.read_csv(\"./dataset/test.csv\", header = 0)\n",
    "\n",
    "\n",
    "train_text = train['comment_text'].fillna(\"no comment\")\n",
    "test_text = test['comment_text'].fillna(\"no comment\")\n",
    "all_text = pd.concat([train_text, test_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=30000)\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    ngram_range=(1, 4),\n",
    "    max_features=30000)\n",
    "vectorizer = make_union(word_vectorizer, char_vectorizer, n_jobs=2)\n",
    "\n",
    "vectorizer.fit(all_text)\n",
    "train_features = vectorizer.transform(train_text)\n",
    "test_features = vectorizer.transform(test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9788002348747701\n",
      "CV score for class severe_toxic is 0.9887815070197937\n",
      "CV score for class obscene is 0.9903319695722619\n",
      "CV score for class threat is 0.9887829180556826\n",
      "CV score for class insult is 0.9828862847385672\n",
      "CV score for class identity_hate is 0.9831331503072307\n",
      "Total CV score is 0.985452677428051\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_features, train_target)\n",
    "    submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "submission.to_csv('submission_logistic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost = pd.read_csv('./submission_Xgb.csv')\n",
    "SVM = pd.read_csv('./submission_SVM.csv')\n",
    "wordbatch = pd.read_csv('./submission_wordbatch.csv')\n",
    "grucnn = pd.read_csv('./submission_GRUgloves.csv')\n",
    "best = pd.read_csv('./submission_GRUfasttext.csv')\n",
    "logistic = pd.read_csv('./submission_logistic.csv')\n",
    "avenger = pd.read_csv('./submission_avenger.csv')\n",
    "LSTMSVM = pd.read_csv('./submission_LSTMSVM.csv')\n",
    "linear = pd.read_csv('./submission_linear.csv')\n",
    "biLSTM = pd.read_csv('./submission_biLSTM.csv')\n",
    "\n",
    "b1 = best.copy()\n",
    "col = best.columns\n",
    "\n",
    "col = col.tolist()\n",
    "col.remove('id')\n",
    "for i in col:\n",
    "    b1[i] = (xgboost[i] + SVM[i] * 2 + wordbatch[i] * 3 + grucnn[i] * 5 + best[i] * 5 + logistic[i] * 2 + avenger[i] * 4 + LSTMSVM[i] * 3 + linear[i] * 3 + biLSTM[i] * 5) /33  \n",
    "    \n",
    "b1.to_csv('combine1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru = pd.read_csv('./submission_GRUfasttext.csv')\n",
    "best = pd.read_csv('./blend_it_all.csv')\n",
    "combine = pd.read_csv('./combine1.csv')\n",
    "\n",
    "b1 = best.copy()\n",
    "col = best.columns\n",
    "\n",
    "col = col.tolist()\n",
    "col.remove('id')\n",
    "for i in col:\n",
    "    b1[i] = (gru[i] * 1 + best[i] * 3 + combine[i] * 2) /6  \n",
    "    \n",
    "b1.to_csv('final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
