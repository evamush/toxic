{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './dataset/crawl-300d-2M.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./dataset/train.csv\", header = 0)\n",
    "test = pd.read_csv(\"./dataset/test.csv\", header = 0)\n",
    "submission = pd.read_csv('./dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train[\"comment_text\"].fillna(\"fillna\")\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "X_test = test[\"comment_text\"].fillna(\"fillna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "max_len = 100\n",
    "embed_size = 300\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train)+list(X_test))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1204: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 300)     9000000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 100, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 100, 160)     182880      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 160)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 160)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 320)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            1926        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 9,184,806\n",
      "Trainable params: 9,184,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape = (max_len, ))\n",
    "    x = Embedding(max_features, embed_size, weights = [embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation='sigmoid')(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "model = get_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_models = 5\n",
    "kf = KFold(n_splits=num_models, random_state=2222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(X_train, y_train, X_test):\n",
    "    \n",
    "    oof_train = np.zeros((X_train.shape[0], 6))\n",
    "    oof_test = np.zeros((num_models, X_test.shape[0],6))\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "        print(\"Fold: {0}\".format(i))\n",
    "        kf_X_train = X_train[train_index]\n",
    "        kf_y_train = y_train[train_index]\n",
    "        kf_X_val = X_train[val_index]\n",
    "        kf_y_val = y_train[val_index]\n",
    "        \n",
    "        RocAuc = RocAucEvaluation(validation_data=(kf_X_val, kf_y_val), interval=1)\n",
    "        model = get_model()\n",
    "        model.fit(kf_X_train, kf_y_train, \n",
    "                 batch_size=batch_size, \n",
    "                 epochs=epochs, \n",
    "                 validation_data=(kf_X_val,kf_y_val),\n",
    "                 callbacks=[RocAuc], \n",
    "                 verbose=1)\n",
    "        \n",
    "        oof_train[val_index,:] = model.predict(kf_X_val)\n",
    "        oof_test[i,:,:] = model.predict(X_test)\n",
    "        \n",
    "    oof_test = np.mean(oof_test, axis=0)\n",
    "    assert oof_test.shape == (X_test.shape[0],6)\n",
    "    assert oof_train.shape == (X_train.shape[0], 6)\n",
    "    \n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/2\n",
      "127648/127656 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9815\n",
      " ROC-AUC - epoch: 1 - score: 0.986696 \n",
      "\n",
      "127656/127656 [==============================] - 1856s 15ms/step - loss: 0.0515 - acc: 0.9815 - val_loss: 0.0428 - val_acc: 0.9835\n",
      "Epoch 2/2\n",
      "127648/127656 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9854\n",
      " ROC-AUC - epoch: 2 - score: 0.986499 \n",
      "\n",
      "127656/127656 [==============================] - 1742s 14ms/step - loss: 0.0378 - acc: 0.9854 - val_loss: 0.0433 - val_acc: 0.9834\n",
      "Fold: 1\n",
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/2\n",
      "127648/127657 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9815\n",
      " ROC-AUC - epoch: 1 - score: 0.984124 \n",
      "\n",
      "127657/127657 [==============================] - 1735s 14ms/step - loss: 0.0515 - acc: 0.9815 - val_loss: 0.0440 - val_acc: 0.9837\n",
      "Epoch 2/2\n",
      "127648/127657 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9853\n",
      " ROC-AUC - epoch: 2 - score: 0.985445 \n",
      "\n",
      "127657/127657 [==============================] - 1734s 14ms/step - loss: 0.0382 - acc: 0.9853 - val_loss: 0.0444 - val_acc: 0.9835\n",
      "Fold: 2\n",
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/2\n",
      "127648/127657 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9815\n",
      " ROC-AUC - epoch: 1 - score: 0.985557 \n",
      "\n",
      "127657/127657 [==============================] - 1742s 14ms/step - loss: 0.0517 - acc: 0.9815 - val_loss: 0.0418 - val_acc: 0.9840\n",
      "Epoch 2/2\n",
      "127648/127657 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9851\n",
      " ROC-AUC - epoch: 2 - score: 0.984419 \n",
      "\n",
      "127657/127657 [==============================] - 1740s 14ms/step - loss: 0.0383 - acc: 0.9851 - val_loss: 0.0427 - val_acc: 0.9838\n",
      "Fold: 3\n",
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/2\n",
      "127648/127657 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.986274 \n",
      "\n",
      "127657/127657 [==============================] - 1743s 14ms/step - loss: 0.0520 - acc: 0.9813 - val_loss: 0.0432 - val_acc: 0.9836\n",
      "Epoch 2/2\n",
      "127648/127657 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9852\n",
      " ROC-AUC - epoch: 2 - score: 0.986978 \n",
      "\n",
      "127657/127657 [==============================] - 1745s 14ms/step - loss: 0.0380 - acc: 0.9852 - val_loss: 0.0435 - val_acc: 0.9835\n",
      "Fold: 4\n",
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/2\n",
      "127648/127657 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9813\n",
      " ROC-AUC - epoch: 1 - score: 0.986582 \n",
      "\n",
      "127657/127657 [==============================] - 1748s 14ms/step - loss: 0.0514 - acc: 0.9813 - val_loss: 0.0446 - val_acc: 0.9832\n",
      "Epoch 2/2\n",
      "127648/127657 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9851\n",
      " ROC-AUC - epoch: 2 - score: 0.987199 \n",
      "\n",
      "127657/127657 [==============================] - 1752s 14ms/step - loss: 0.0379 - acc: 0.9851 - val_loss: 0.0436 - val_acc: 0.9835\n"
     ]
    }
   ],
   "source": [
    "oof_train, oof_test = get_oof(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>0.036050</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "id                                                                       \n",
       "0000997932d777bf  0.000270      0.000007  0.000097  0.000004  0.000053   \n",
       "000103f0d9cfb60f  0.003815      0.000065  0.001260  0.000025  0.000603   \n",
       "000113f07ec002fd  0.001735      0.000033  0.000326  0.000015  0.000185   \n",
       "0001b41b1c6bb37e  0.000073      0.000004  0.000035  0.000005  0.000059   \n",
       "0001d958c54c6e35  0.036050      0.000212  0.003500  0.000354  0.006007   \n",
       "\n",
       "                  identity_hate  \n",
       "id                               \n",
       "0000997932d777bf       0.000039  \n",
       "000103f0d9cfb60f       0.000101  \n",
       "000113f07ec002fd       0.000065  \n",
       "0001b41b1c6bb37e       0.000022  \n",
       "0001d958c54c6e35       0.000311  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_train = pd.DataFrame(index=train.id, \n",
    "                             columns=[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"],\n",
    "                             data = oof_train)\n",
    "stacked_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>0.996893</td>\n",
       "      <td>0.512090</td>\n",
       "      <td>0.981384</td>\n",
       "      <td>0.108628</td>\n",
       "      <td>0.945050</td>\n",
       "      <td>0.247938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "id                                                                       \n",
       "00001cee341fdb12  0.996893      0.512090  0.981384  0.108628  0.945050   \n",
       "0000247867823ef7  0.000193      0.000015  0.000097  0.000007  0.000072   \n",
       "00013b17ad220c46  0.001615      0.000128  0.000695  0.000075  0.000439   \n",
       "00017563c3f7919a  0.000435      0.000031  0.000276  0.000064  0.000232   \n",
       "00017695ad8997eb  0.009032      0.000230  0.001415  0.000177  0.000834   \n",
       "\n",
       "                  identity_hate  \n",
       "id                               \n",
       "00001cee341fdb12       0.247938  \n",
       "0000247867823ef7       0.000017  \n",
       "00013b17ad220c46       0.000136  \n",
       "00017563c3f7919a       0.000025  \n",
       "00017695ad8997eb       0.000126  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_test = pd.DataFrame(index=test.id,\n",
    "                           columns=[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"],\n",
    "                           data=oof_test)\n",
    "stacked_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
